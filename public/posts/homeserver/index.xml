<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Homeserver on Jan's site</title><link>https://jschall.net/posts/homeserver/</link><description>Recent content in Homeserver on Jan's site</description><generator>Hugo</generator><language>en-US</language><copyright>Copyright Â© 2024, Jan Schall.</copyright><lastBuildDate>Mon, 12 Aug 2024 10:34:13 +0200</lastBuildDate><atom:link href="https://jschall.net/posts/homeserver/index.xml" rel="self" type="application/rss+xml"/><item><title>Smarthome plasmaball</title><link>https://jschall.net/posts/smarthome-plasmaball/</link><pubDate>Mon, 12 Aug 2024 10:34:13 +0200</pubDate><guid>https://jschall.net/posts/smarthome-plasmaball/</guid><description>So, yeah, I guess I don&amp;rsquo;t need to add much more than the title already reveals: I built a smarthome integration for my plasma ball. Why? I don&amp;rsquo;t know, I thought it would be a fun idea, but in the end it got much worse than I thought, because I don&amp;rsquo;t have really a good practice in soldering and electrical engineering. Good conditions, to start such a project, I think.</description></item><item><title>Run LLMs locally</title><link>https://jschall.net/posts/ollama_web_ui/</link><pubDate>Sun, 05 May 2024 00:00:00 +0000</pubDate><guid>https://jschall.net/posts/ollama_web_ui/</guid><description>How to Run Open-Source LLMs on a Local Computer Without Compromising on a Specific Use Case? Today, I will show you how to run LLMs locally on a computer or home server using Ollama in combination with the OpenUI web interface. What is Ollama? First, Ollama is an engine that allows you to run Large Language Models (LLMs) on your own computer, so no personal data from sessions, like those in ChatGPT, is sent to companies.</description></item><item><title>Building an own cloud</title><link>https://jschall.net/posts/buidling-an-own-cloud/</link><pubDate>Sun, 28 Apr 2024 00:00:00 +0000</pubDate><guid>https://jschall.net/posts/buidling-an-own-cloud/</guid><description>In recent weeks, I have been using my own cloud to back up my photos and videos from my smartphone and laptop by using a containerized Photoprism instance. Today, I want to share how I set up my server and Docker environment to get everything running.
Installing the Server&amp;rsquo;s Operating System First, you should use a separate computer so your own cloud is always accessible when you need to access your photos.</description></item></channel></rss>